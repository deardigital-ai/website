name: Discussion Assistant

on:
  discussion:
    types: [created]
  discussion_comment:
    types: [created, edited]

jobs:
  respond-to-discussion:
    runs-on: self-hosted
    
    steps:
      - name: Initialize workflow log
        id: init-log
        run: |
          # Create a log file with initial details
          echo "# Workflow Execution Log - $(date)" > workflow_debug.log
          echo "## Run ID: ${{ github.run_id }}" >> workflow_debug.log
          echo "## Event: ${{ github.event_name }}" >> workflow_debug.log
          echo "## Repository: ${{ github.repository }}" >> workflow_debug.log
          echo "## Workflow: ${{ github.workflow }}" >> workflow_debug.log
          echo "## Run Number: ${{ github.run_number }}" >> workflow_debug.log
          echo "## Actor: ${{ github.actor }}" >> workflow_debug.log
          echo "## Start Time: $(date)" >> workflow_debug.log
          echo "" >> workflow_debug.log
          echo "## Step Logs:" >> workflow_debug.log
          
          # Make the log file available to all steps
          echo "log_file=workflow_debug.log" >> $GITHUB_OUTPUT
      
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'
      
      - name: Log setup steps
        run: |
          echo "### Setup steps completed at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          echo "- Repository checkout: ✅" >> ${{ steps.init-log.outputs.log_file }}
          echo "- Node.js setup: ✅" >> ${{ steps.init-log.outputs.log_file }}
          echo "" >> ${{ steps.init-log.outputs.log_file }}
          
      - name: Get discussion content
        id: get-content
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const eventName = context.eventName;
            let discussionContent = '';
            let discussionId = '';
            let commentId = null;
            
            if (eventName === 'discussion') {
              const discussion = context.payload.discussion;
              discussionContent = discussion.title + '\n\n' + discussion.body;
              discussionId = discussion.node_id;
              
              // Log discussion details
              const fs = require('fs');
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `### Retrieved Discussion at ${new Date().toISOString()}\n` +
                `- Title: ${discussion.title}\n` +
                `- Discussion ID: ${discussionId}\n` +
                `- Content length: ${discussionContent.length} characters\n\n`
              );
            } else if (eventName === 'discussion_comment') {
              const comment = context.payload.comment;
              const discussion = context.payload.discussion;
              discussionContent = discussion.title + '\n\n' + comment.body;
              discussionId = discussion.node_id;
              commentId = comment.node_id;
              
              // Log comment details
              const fs = require('fs');
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `### Retrieved Discussion Comment at ${new Date().toISOString()}\n` +
                `- Discussion Title: ${discussion.title}\n` +
                `- Discussion ID: ${discussionId}\n` +
                `- Comment ID: ${commentId}\n` +
                `- Content length: ${discussionContent.length} characters\n\n`
              );
            }
            
            // Get all previous comments to provide context
            let allContent = discussionContent;
            if (eventName === 'discussion_comment') {
              const { repository } = context.payload;
              const query = `
                query($owner: String!, $repo: String!, $discussionNumber: Int!) {
                  repository(owner: $owner, name: $repo) {
                    discussion(number: $discussionNumber) {
                      comments(first: 100) {
                        nodes {
                          author {
                            login
                          }
                          body
                          createdAt
                        }
                      }
                    }
                  }
                }
              `;
              
              const variables = {
                owner: repository.owner.login,
                repo: repository.name,
                discussionNumber: context.payload.discussion.number
              };
              
              try {
                const result = await github.graphql(query, variables);
                const comments = result.repository.discussion.comments.nodes;
                
                // Log fetched comments
                const fs = require('fs');
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                  `- Retrieved ${comments.length} previous comments\n\n`
                );
                
                // Append all previous comments to provide context
                if (comments.length > 0) {
                  allContent += '\n\nPrevious comments:\n';
                  for (const comment of comments) {
                    allContent += `\n@${comment.author.login} said: ${comment.body}\n`;
                  }
                }
              } catch (error) {
                // Log error
                const fs = require('fs');
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                  `- ❌ Error retrieving previous comments: ${error.message}\n\n`
                );
              }
            }
            
            core.setOutput('discussion_content', allContent);
            core.setOutput('discussion_id', discussionId);
            core.setOutput('comment_id', commentId);
      
      - name: Call Together AI API
        id: ai-response
        run: |
          echo "### Calling Together AI API at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          echo "- Model: deepseek-ai/DeepSeek-R1" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create a properly escaped JSON version of the content
          CONTENT_TO_PROCESS="${{ steps.get-content.outputs.discussion_content }}"
          
          # Check if content is too short
          if [[ ${#CONTENT_TO_PROCESS} -lt 10 ]]; then
            echo "- ⚠️ Content is very short (${#CONTENT_TO_PROCESS} characters). Adding context." >> ${{ steps.init-log.outputs.log_file }}
            CONTENT_TO_PROCESS="This is a short message in a GitHub discussion: ${CONTENT_TO_PROCESS}"
          fi
          
          echo "- Input content length: ${#CONTENT_TO_PROCESS} bytes" >> ${{ steps.init-log.outputs.log_file }}
          
          # Store the content in a file for processing
          echo "$CONTENT_TO_PROCESS" > input_content.txt
          
          # Use a more reliable method to create the JSON payload
          # First, escape the content properly for JSON
          ESCAPED_CONTENT=$(cat input_content.txt | sed 's/"/\\"/g' | sed ':a;N;$!ba;s/\n/\\n/g')
          
          # Create the JSON payload with properly escaped content
          PAYLOAD="{\"model\":\"deepseek-ai/DeepSeek-R1\",\"messages\":[{\"role\":\"user\",\"content\":\"$ESCAPED_CONTENT\"}]}"
          
          echo "- JSON payload created successfully" >> ${{ steps.init-log.outputs.log_file }}
          
          # Start timer
          START_TIME=$(date +%s)
          
          # Add retry logic for API calls
          MAX_RETRIES=3
          RETRY_COUNT=0
          SUCCESS=false
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" != "true" ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "- 🔄 Retry attempt $RETRY_COUNT..." >> ${{ steps.init-log.outputs.log_file }}
              sleep $(( RETRY_COUNT * 2 ))  # Progressive backoff
            fi
            
            RESPONSE=$(curl -s -X POST "https://api.together.xyz/v1/chat/completions" \
              -H "Authorization: Bearer ${{ secrets.TOGETHER_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD")
            
            # Check if the response contains an error
            ERROR_CHECK=$(echo $RESPONSE | jq -r 'if has("error") then .error.message else "no_error" end')
            
            if [[ "$ERROR_CHECK" == "no_error" ]]; then
              # Check if we can extract content (additional validation)
              CONTENT_CHECK=$(echo $RESPONSE | jq -r 'if has("choices") and (.choices | length > 0) and has("choices"[0].message.content) then "has_content" else "no_content" end')
              
              if [[ "$CONTENT_CHECK" == "has_content" ]]; then
                SUCCESS=true
              else
                echo "- ⚠️ API returned a response but no valid content found (attempt $((RETRY_COUNT+1)))" >> ${{ steps.init-log.outputs.log_file }}
              fi
            else
              echo "- ⚠️ API Error (attempt $((RETRY_COUNT+1))): $ERROR_CHECK" >> ${{ steps.init-log.outputs.log_file }}
            fi
            
            RETRY_COUNT=$((RETRY_COUNT+1))
          done
          
          # End timer
          END_TIME=$(date +%s)
          ELAPSED_TIME=$((END_TIME - START_TIME))
          
          echo "- API interaction completed in ${ELAPSED_TIME} seconds" >> ${{ steps.init-log.outputs.log_file }}
          
          if [[ "$SUCCESS" == "true" ]]; then
            # Extract the content from the response
            CONTENT=$(echo $RESPONSE | jq -r '.choices[0].message.content')
            
            # Log API response details
            echo "- ✅ API response successful" >> ${{ steps.init-log.outputs.log_file }}
            echo "- Response length: ${#CONTENT} bytes" >> ${{ steps.init-log.outputs.log_file }}
            
            # Check if content is empty or too short
            if [[ -z "$CONTENT" || ${#CONTENT} -lt 5 ]]; then
              echo "- ⚠️ Response content too short or empty. Using default response." >> ${{ steps.init-log.outputs.log_file }}
              CONTENT="I'm sorry, I couldn't generate a proper response. Please try again with more details."
            fi
          else
            # Use a fallback message if all retries failed
            echo "- ❌ All API attempts failed. Using fallback message." >> ${{ steps.init-log.outputs.log_file }}
            CONTENT="I apologize, but I'm currently experiencing technical difficulties. Your message has been received, and we'll address it as soon as possible."
          fi
          
          echo "" >> ${{ steps.init-log.outputs.log_file }}
          
          # Save the content to a file to preserve newlines and formatting
          echo "$CONTENT" > response.txt
          
          # Set the content as an output in a format that can be used in the next step
          echo "content<<EOF" >> $GITHUB_OUTPUT
          cat response.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      
      - name: Post response to discussion
        id: post-response
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const eventName = context.eventName;
            const discussionId = '${{ steps.get-content.outputs.discussion_id }}';
            const commentId = '${{ steps.get-content.outputs.comment_id }}';
            const aiResponse = `${{ steps.ai-response.outputs.content }}`;
            
            // Validate we have a proper response to post
            if (!aiResponse || aiResponse.trim().length < 3) {
              core.setFailed('AI response is empty or too short to post');
              return;
            }
            
            const fs = require('fs');
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `### Posting AI Response at ${new Date().toISOString()}\n` +
              `- Event type: ${eventName}\n` +
              `- Discussion ID: ${discussionId}\n` +
              (commentId ? `- Comment ID: ${commentId}\n` : '') +
              `- Response length: ${aiResponse.length} characters\n\n`
            );
            
            try {
              // Add a comment with the AI response
              if (eventName === 'discussion') {
                // Add a new comment to the discussion
                const result = await github.graphql(`
                  mutation($discussionId: ID!, $body: String!) {
                    addDiscussionComment(input: {discussionId: $discussionId, body: $body}) {
                      comment {
                        id
                      }
                    }
                  }
                `, {
                  discussionId: discussionId,
                  body: aiResponse
                });
                
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                  `- ✅ Successfully posted comment to discussion\n` +
                  `- Comment ID: ${result.addDiscussionComment.comment.id}\n\n`
                );
              } else if (eventName === 'discussion_comment') {
                try {
                  // First try to reply directly to the comment
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Attempting to reply directly to comment\n`);
                  
                  const result = await github.graphql(`
                    mutation($discussionId: ID!, $body: String!, $replyToId: ID) {
                      addDiscussionComment(input: {discussionId: $discussionId, body: $body, replyToId: $replyToId}) {
                        comment {
                          id
                        }
                      }
                    }
                  `, {
                    discussionId: discussionId,
                    body: aiResponse,
                    replyToId: commentId
                  });
                  
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                    `- ✅ Successfully posted reply to comment\n` +
                    `- Reply ID: ${result.addDiscussionComment.comment.id}\n\n`
                  );
                } catch (replyError) {
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                    `- ⚠️ Error replying directly: ${replyError.message}\n` +
                    `- Will try to find parent comment or fallback to a new comment\n`
                  );
                  
                  // Check if this is a "already in thread" error
                  const alreadyInThreadError = replyError.message.includes("Parent comment is already in a thread");
                  
                  if (alreadyInThreadError) {
                    try {
                      // Get the discussion to find the parent comment of the thread
                      const { repository } = context.payload;
                      const discussionNumber = context.payload.discussion.number;
                      
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Looking for parent comment in discussion #${discussionNumber}\n`
                      );
                      
                      // First, get the discussion and all its comments and replies
                      const commentQuery = `
                        query($owner: String!, $repo: String!, $number: Int!) {
                          repository(owner: $owner, name: $repo) {
                            discussion(number: $number) {
                              comments(first: 100) {
                                nodes {
                                  id
                                  replies(first: 50) {
                                    nodes {
                                      id
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      `;
                      
                      const variables = {
                        owner: repository.owner.login,
                        repo: repository.name,
                        number: discussionNumber
                      };
                      
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Querying discussion with variables: ${JSON.stringify(variables)}\n`
                      );
                      
                      const discussionData = await github.graphql(commentQuery, variables);
                      
                      if (!discussionData || !discussionData.repository || !discussionData.repository.discussion) {
                        throw new Error("Failed to retrieve discussion data");
                      }
                      
                      const comments = discussionData.repository.discussion.comments.nodes;
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Found ${comments.length} top-level comments\n`
                      );
                      
                      // Find a parent comment that contains our comment ID in its replies
                      let parentCommentId = null;
                      
                      // Debug log the comment we're looking for
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Looking for comment with ID: ${commentId}\n`
                      );
                      
                      for (const comment of comments) {
                        const replies = comment.replies.nodes;
                        fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                          `- Checking comment ${comment.id} with ${replies.length} replies\n`
                        );
                        
                        for (const reply of replies) {
                          if (reply.id === commentId) {
                            parentCommentId = comment.id;
                            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                              `- Match found! Comment ${commentId} is a reply to ${parentCommentId}\n`
                            );
                            break;
                          }
                        }
                        
                        if (parentCommentId) break;
                      }
                      
                      if (parentCommentId) {
                        fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                          `- Found parent comment ID: ${parentCommentId}\n`
                        );
                        
                        // Reply to the parent comment
                        const parentResult = await github.graphql(`
                          mutation($discussionId: ID!, $body: String!, $replyToId: ID!) {
                            addDiscussionComment(input: {discussionId: $discussionId, body: $body, replyToId: $replyToId}) {
                              comment {
                                id
                              }
                            }
                          }
                        `, {
                          discussionId: discussionId,
                          body: aiResponse,
                          replyToId: parentCommentId
                        });
                        
                        fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                          `- ✅ Successfully posted reply to parent comment\n` +
                          `- Reply ID: ${parentResult.addDiscussionComment.comment.id}\n\n`
                        );
                      } else {
                        throw new Error("Could not find parent comment for this reply");
                      }
                    } catch (parentError) {
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- ⚠️ Error finding parent: ${parentError.message}\n` +
                        `- Falling back to posting a new top-level comment\n`
                      );
                      
                      // Just post a new comment without specifying replyToId
                      const fallbackResult = await github.graphql(`
                        mutation($discussionId: ID!, $body: String!) {
                          addDiscussionComment(input: {discussionId: $discussionId, body: $body}) {
                            comment {
                              id
                            }
                          }
                        }
                      `, {
                        discussionId: discussionId,
                        body: aiResponse
                      });
                      
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- ✅ Successfully posted fallback top-level comment\n` +
                        `- Comment ID: ${fallbackResult.addDiscussionComment.comment.id}\n\n`
                      );
                    }
                  } else {
                    // For other types of errors, just fail
                    throw replyError;
                  }
                }
              }
            } catch (error) {
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `- ❌ Error posting response: ${error.message}\n\n`
              );
              core.setFailed(`Error posting response: ${error.message}`);
            }
      
      - name: Get workflow run logs for analysis
        id: get-logs
        continue-on-error: true  # Don't fail the workflow if this step fails
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { owner, repo } = context.repo;
            const workflowName = 'Discussion Assistant';
            
            const fs = require('fs');
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `### Attempting to Get Workflow Logs at ${new Date().toISOString()}\n`
            );
            
            try {
              // Get workflow ID by name
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Fetching workflows for repo\n`);
              const { data: workflows } = await github.rest.actions.listRepoWorkflows({
                owner,
                repo
              });
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Found ${workflows.workflows.length} workflows\n`);
              
              const workflow = workflows.workflows.find(w => w.name === workflowName);
              if (!workflow) {
                core.warning(`Could not find workflow with name: ${workflowName}`);
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Could not find workflow with name: ${workflowName}\n\n`);
                return 'no_workflow_found';
              }
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Found workflow ID: ${workflow.id}\n`);
              
              // Get workflow runs
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Fetching workflow runs\n`);
              const { data: runs } = await github.rest.actions.listWorkflowRuns({
                owner,
                repo,
                workflow_id: workflow.id,
                per_page: 5  // Get the most recent runs
              });
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Found ${runs.workflow_runs ? runs.workflow_runs.length : 0} workflow runs\n`);
              
              if (!runs.workflow_runs || runs.workflow_runs.length <= 1) {
                core.warning('Not enough workflow runs found for analysis');
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Not enough workflow runs found for analysis\n\n`);
                return 'no_runs_found';
              }
              
              // Get second latest workflow run (to avoid getting the currently running workflow)
              const previousRun = runs.workflow_runs[1];
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Using run ID: ${previousRun.id} (${previousRun.created_at})\n`);
              
              try {
                // Try to get logs URL
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Attempting to download workflow logs\n`);
                const { data: logsUrl } = await github.rest.actions.downloadWorkflowRunLogs({
                  owner,
                  repo,
                  run_id: previousRun.id
                });
                
                // The API returns a URL directly instead of an object with a url property
                const logsDownloadUrl = typeof logsUrl === 'string' ? logsUrl : logsUrl.url;
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Logs URL obtained: ${logsDownloadUrl ? 'Yes' : 'No'}\n`);
                
                if (!logsDownloadUrl) {
                  throw new Error('No logs URL available');
                }
                
                // Download logs using curl
                const { execSync } = require('child_process');
                
                // Download the logs (which is a zip file)
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Downloading logs\n`);
                execSync(`curl -L "${logsDownloadUrl}" -o logs.zip`);
                
                // Create directory for logs
                execSync('mkdir -p workflow_logs');
                
                // Extract the logs
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Extracting logs\n`);
                execSync('unzip -o logs.zip -d workflow_logs');
                
                // Combine all log files into a single file for analysis
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Combining log files\n`);
                execSync('cat workflow_logs/*.txt > combined_logs.txt');
                const logContent = fs.readFileSync('combined_logs.txt', 'utf8');
                
                // Read the workflow file
                const workflowContent = fs.readFileSync('.github/workflows/discussion-assistant.yml', 'utf8');
                
                // Store the content for the next step
                fs.writeFileSync('workflow_file.yml', workflowContent);
                
                // Set outputs in a format that works with GitHub Actions
                core.setOutput('result', 'success');
                core.setOutput('has_logs', 'true');
                
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ✅ Logs and workflow file prepared successfully\n\n`);
                return 'success';
              } catch (logsError) {
                // If we can't get logs, we'll just analyze the workflow file without logs
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Error getting logs: ${logsError.message}\n`);
                
                // Read the workflow file
                const workflowContent = fs.readFileSync('.github/workflows/discussion-assistant.yml', 'utf8');
                
                // Store the content for the next step
                fs.writeFileSync('workflow_file.yml', workflowContent);
                
                // Set outputs in a format that works with GitHub Actions
                core.setOutput('result', 'success');
                core.setOutput('has_logs', 'false');
                
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ⚠️ Only workflow file prepared (no logs available)\n\n`);
                return 'success_without_logs';
              }
            } catch (error) {
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Error in workflow analysis preparation: ${error.message}\n\n`);
              core.warning(`Error in workflow analysis preparation: ${error.message}`);
              return 'error';
            }
      
      - name: Analyze logs and suggest improvements
        id: analyze-logs
        if: success() && steps.get-logs.outputs.result != ''
        run: |
          echo "### Starting Workflow Analysis at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          
          # Check if the workflow_file.yml exists before proceeding
          if [ ! -f "workflow_file.yml" ]; then
            echo "::warning::workflow_file.yml not found. Skipping analysis."
            echo "- ❌ workflow_file.yml not found. Skipping analysis." >> ${{ steps.init-log.outputs.log_file }}
            exit 0
          fi
          
          echo "- Workflow file found" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create the analysis prompt based on available data
          if [ "${{ steps.get-logs.outputs.has_logs }}" = "true" ] && [ -f "combined_logs.txt" ]; then
            echo "- Using workflow file and logs for analysis" >> ${{ steps.init-log.outputs.log_file }}
            # Get workflow content and logs for analysis
            WORKFLOW_CONTENT=$(cat workflow_file.yml)
            LOG_CONTENT=$(cat combined_logs.txt)
            
            # Create a JSON-safe prompt for analysis
            ANALYSIS_PROMPT="Analyze the following GitHub Action workflow and its execution logs to identify improvements."
            
            # Store the workflow content and logs in files
            echo "$WORKFLOW_CONTENT" > workflow_content.txt
            echo "$LOG_CONTENT" > log_content.txt
            
          else
            echo "- Using only workflow file for analysis (no logs available)" >> ${{ steps.init-log.outputs.log_file }}
            # Only analyze the workflow file without logs
            WORKFLOW_CONTENT=$(cat workflow_file.yml)
            
            # Create a JSON-safe prompt for analysis
            ANALYSIS_PROMPT="Analyze the following GitHub Action workflow configuration to identify improvements."
            
            # Store the workflow content in a file
            echo "$WORKFLOW_CONTENT" > workflow_content.txt
            echo "" > log_content.txt
          fi
          
          # Start timer
          START_TIME=$(date +%s)
          
          echo "- Preparing analysis request to Together AI API" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create JSON payload using jq for proper escaping
          if [ "${{ steps.get-logs.outputs.has_logs }}" = "true" ] && [ -f "combined_logs.txt" ]; then
            PAYLOAD=$(jq -n \
              --arg prompt "$ANALYSIS_PROMPT" \
              --rawfile workflow workflow_content.txt \
              --rawfile logs log_content.txt \
              '{
                "model": "deepseek-ai/DeepSeek-R1",
                "messages": [{
                  "role": "user", 
                  "content": ($prompt + "\n\nWORKFLOW FILE:\n```yaml\n" + $workflow + "\n```\n\nEXECUTION LOGS:\n```\n" + $logs + "\n```\n\nPlease analyze these and identify potential issues, inefficiencies, or improvements. Consider error patterns, performance bottlenecks, best practices, security concerns, reliability improvements, and code quality suggestions. Format your response as a structured GitHub issue with detailed explanations, specific solutions with example code, and benefits of implementing changes.")
                }]
              }')
          else
            PAYLOAD=$(jq -n \
              --arg prompt "$ANALYSIS_PROMPT" \
              --rawfile workflow workflow_content.txt \
              '{
                "model": "deepseek-ai/DeepSeek-R1",
                "messages": [{
                  "role": "user", 
                  "content": ($prompt + "\n\nWORKFLOW FILE:\n```yaml\n" + $workflow + "\n```\n\nPlease analyze this configuration to identify potential issues, inefficiencies, or improvements. Consider best practices, security concerns, reliability improvements, code quality suggestions, and error handling. Format your response as a structured GitHub issue with detailed explanations, specific solutions with example code, and benefits of implementing changes.")
                }]
              }')
          fi
          
          echo "- JSON payload created for analysis" >> ${{ steps.init-log.outputs.log_file }}
          
          # Add retry logic for API calls
          MAX_RETRIES=3
          RETRY_COUNT=0
          SUCCESS=false
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" != "true" ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "- 🔄 Retry attempt $RETRY_COUNT for analysis..." >> ${{ steps.init-log.outputs.log_file }}
              sleep $(( RETRY_COUNT * 2 ))  # Progressive backoff
            fi
            
            # Call Together AI API for analysis
            RESPONSE=$(curl -s -X POST "https://api.together.xyz/v1/chat/completions" \
              -H "Authorization: Bearer ${{ secrets.TOGETHER_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD")
            
            # Check if the response contains an error
            ERROR_CHECK=$(echo $RESPONSE | jq -r 'if has("error") then .error.message else "no_error" end')
            
            if [[ "$ERROR_CHECK" == "no_error" ]]; then
              # Check if we can extract content (additional validation)
              CONTENT_CHECK=$(echo $RESPONSE | jq -r 'if has("choices") and (.choices | length > 0) and has("choices"[0].message.content) then "has_content" else "no_content" end')
              
              if [[ "$CONTENT_CHECK" == "has_content" ]]; then
                SUCCESS=true
              else
                echo "- ⚠️ API returned a response but no valid content found for analysis (attempt $((RETRY_COUNT+1)))" >> ${{ steps.init-log.outputs.log_file }}
              fi
            else
              echo "- ⚠️ API Error during analysis (attempt $((RETRY_COUNT+1))): $ERROR_CHECK" >> ${{ steps.init-log.outputs.log_file }}
            fi
            
            RETRY_COUNT=$((RETRY_COUNT+1))
          done
          
          # End timer
          END_TIME=$(date +%s)
          ELAPSED_TIME=$((END_TIME - START_TIME))
          
          echo "- Analysis completed in ${ELAPSED_TIME} seconds" >> ${{ steps.init-log.outputs.log_file }}
          
          if [[ "$SUCCESS" == "true" ]]; then
            # Extract the content from the response
            ANALYSIS=$(echo $RESPONSE | jq -r '.choices[0].message.content')
            
            # Check for minimum analysis length
            if [[ -z "$ANALYSIS" || ${#ANALYSIS} -lt 50 ]]; then
              echo "- ⚠️ Analysis too short or empty. No suggestions available." >> ${{ steps.init-log.outputs.log_file }}
              echo "has_suggestions=false" >> $GITHUB_OUTPUT
            else
              # Save the analysis to a file
              echo "$ANALYSIS" > workflow_analysis.txt
              
              # More robust check for meaningful suggestions
              if grep -q -E 'improvement|issue|suggestion|recommend|fix|enhance|optimize|refactor|update|upgrade|modify' workflow_analysis.txt; then
                echo "- ✅ Analysis found suggestions for improvement" >> ${{ steps.init-log.outputs.log_file }}
                echo "has_suggestions=true" >> $GITHUB_OUTPUT
                
                # Format for GitHub output
                echo "analysis<<EOF" >> $GITHUB_OUTPUT
                cat workflow_analysis.txt >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              else
                echo "- ℹ️ No significant suggestions found in analysis" >> ${{ steps.init-log.outputs.log_file }}
                echo "has_suggestions=false" >> $GITHUB_OUTPUT
              fi
            fi
          else
            echo "- ❌ Failed to get analysis after $MAX_RETRIES attempts" >> ${{ steps.init-log.outputs.log_file }}
            echo "has_suggestions=false" >> $GITHUB_OUTPUT
          fi
          
          echo "" >> ${{ steps.init-log.outputs.log_file }}
      
      - name: Create improvement issue
        id: create-issue
        if: steps.analyze-logs.outputs.has_suggestions == 'true'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { owner, repo } = context.repo;
            const analysis = `${{ steps.analyze-logs.outputs.analysis }}`;
            
            const fs = require('fs');
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `### Creating Improvement Issue at ${new Date().toISOString()}\n`
            );
            
            try {
              // Determine a good title from the analysis (take first line or generate one)
              let title = "Workflow Improvement Suggestions for Discussion Assistant";
              const firstLine = analysis.split('\n')[0].trim();
              if (firstLine && firstLine.length > 10 && firstLine.length < 100) {
                title = firstLine;
              }
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Issue title: "${title}"\n`);
              
              // Get repository owner for assignee
              const { data: repoData } = await github.rest.repos.get({
                owner,
                repo
              });
              
              const assignee = repoData.owner.login;
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Assignee: ${assignee}\n`);
              
              // Create the issue
              const { data: issue } = await github.rest.issues.create({
                owner,
                repo,
                title,
                body: analysis,
                labels: ['automation', 'improvement', 'workflow'],
                assignees: [assignee]
              });
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `- ✅ Successfully created issue #${issue.number}\n` +
                `- Issue URL: ${issue.html_url}\n\n`
              );
              
              return {
                issue_number: issue.number,
                issue_url: issue.html_url
              };
            } catch (error) {
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `- ❌ Error creating issue: ${error.message}\n\n`
              );
              core.setFailed(`Error creating issue: ${error.message}`);
              return null;
            }
      
      - name: Create workflow log discussion
        id: create-log-discussion
        if: always()  # Run even if previous steps failed
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { owner, repo } = context.repo;
            
            try {
              const fs = require('fs');
              
              // Append final execution stats
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `\n## Workflow Execution Summary\n` +
                `- End Time: ${new Date().toISOString()}\n` +
                `- Run URL: https://github.com/${owner}/${repo}/actions/runs/${{ github.run_id }}\n` +
                `- Workflow File: https://github.com/${owner}/${repo}/blob/${{ github.ref_name }}/.github/workflows/discussion-assistant.yml\n`
              );
              
              // Read the complete log file
              const logContent = fs.readFileSync('${{ steps.init-log.outputs.log_file }}', 'utf8');
              
              // Create a new discussion with the logs
              const result = await github.graphql(`
                mutation($input: CreateDiscussionInput!) {
                  createDiscussion(input: $input) {
                    discussion {
                      id
                      url
                    }
                  }
                }
              `, {
                input: {
                  repositoryId: context.payload.repository.node_id,
                  categoryId: context.payload.repository.discussion_category_node_id || "DIC_kwDOLnNa0M4CT3wz", // Use a default if not available
                  body: logContent,
                  title: `Analysis of workflow #${{ github.run_number }} - ${new Date().toISOString().split('T')[0]}`
                }
              });
              
              console.log(`Created log discussion: ${result.createDiscussion.discussion.url}`);
              return result.createDiscussion.discussion.url;
            } catch (error) {
              console.error(`Error creating log discussion: ${error.message}`);
              
              // If we can't create a discussion through GraphQL, try to create an issue instead
              try {
                const fs = require('fs');
                const logContent = fs.readFileSync('${{ steps.init-log.outputs.log_file }}', 'utf8');
                
                const { data: issue } = await github.rest.issues.create({
                  owner,
                  repo,
                  title: `Analysis of workflow #${{ github.run_number }} - ${new Date().toISOString().split('T')[0]}`,
                  body: logContent,
                  labels: ['log', 'automation', 'workflow']
                });
                
                console.log(`Created log issue: ${issue.html_url}`);
                return issue.html_url;
              } catch (issueError) {
                console.error(`Error creating fallback log issue: ${issueError.message}`);
                return null;
              }
            } 