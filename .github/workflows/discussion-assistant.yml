name: Discussion Assistant

on:
  discussion:
    types: [created]
  discussion_comment:
    types: [created, edited]

jobs:
  respond-to-discussion:
    runs-on: self-hosted
    
    steps:
      - name: Initialize workflow log
        id: init-log
        run: |
          # Create a log file with initial details
          echo "# Workflow Execution Log - $(date)" > workflow_debug.log
          echo "## Run ID: ${{ github.run_id }}" >> workflow_debug.log
          echo "## Event: ${{ github.event_name }}" >> workflow_debug.log
          echo "## Repository: ${{ github.repository }}" >> workflow_debug.log
          echo "## Workflow: ${{ github.workflow }}" >> workflow_debug.log
          echo "## Run Number: ${{ github.run_number }}" >> workflow_debug.log
          echo "## Actor: ${{ github.actor }}" >> workflow_debug.log
          echo "## Start Time: $(date)" >> workflow_debug.log
          echo "" >> workflow_debug.log
          echo "## Step Logs:" >> workflow_debug.log
          
          # Make the log file available to all steps
          echo "log_file=workflow_debug.log" >> $GITHUB_OUTPUT
      
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'
      
      - name: Log setup steps
        run: |
          echo "### Setup steps completed at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          echo "- Repository checkout: ✅" >> ${{ steps.init-log.outputs.log_file }}
          echo "- Node.js setup: ✅" >> ${{ steps.init-log.outputs.log_file }}
          echo "" >> ${{ steps.init-log.outputs.log_file }}
          
      - name: Get discussion content
        id: get-content
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const eventName = context.eventName;
            let discussionContent = '';
            let discussionId = '';
            let commentId = null;
            
            console.log('EVENT NAME:', eventName);
            console.log('EVENT PAYLOAD:', JSON.stringify(context.payload, null, 2).substring(0, 1000) + '...');
            
            const fs = require('fs');
            
            // Create a directory for content files
            fs.mkdirSync('content_files', { recursive: true });
            
            if (eventName === 'discussion') {
              const discussion = context.payload.discussion;
              discussionContent = discussion.title + '\n\n' + discussion.body;
              discussionId = discussion.node_id;
              
              // Log discussion details
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `### Retrieved Discussion at ${new Date().toISOString()}\n` +
                `- Title: ${discussion.title}\n` +
                `- Discussion ID: ${discussionId}\n` +
                `- Content length: ${discussionContent.length} characters\n\n`
              );
            } else if (eventName === 'discussion_comment') {
              const comment = context.payload.comment;
              const discussion = context.payload.discussion;
              discussionContent = discussion.title + '\n\n' + comment.body;
              discussionId = discussion.node_id;
              commentId = comment.node_id;
              
              // Log comment details
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `### Retrieved Discussion Comment at ${new Date().toISOString()}\n` +
                `- Discussion Title: ${discussion.title}\n` +
                `- Discussion ID: ${discussionId}\n` +
                `- Comment ID: ${commentId}\n` +
                `- Content length: ${discussionContent.length} characters\n` +
                `- Comment body preview: ${comment.body.substring(0, 100)}...\n\n`
              );
            }
            
            // Get all previous comments to provide context
            let allContent = discussionContent;
            if (eventName === 'discussion_comment') {
              const { repository } = context.payload;
              
              function createPreviousCommentsQuery() {
                return `
                  query($owner: String!, $repo: String!, $discussionNumber: Int!) {
                    repository(owner: $owner, name: $repo) {
                      discussion(number: $discussionNumber) {
                        comments(first: 100) {
                          nodes {
                            author {
                              login
                            }
                            body
                            createdAt
                          }
                        }
                      }
                    }
                  }
                `;
              }
              
              const variables = {
                owner: repository.owner.login,
                repo: repository.name,
                discussionNumber: context.payload.discussion.number
              };
              
              try {
                const result = await github.graphql(createPreviousCommentsQuery(), variables);
                const comments = result.repository.discussion.comments.nodes;
                
                // Log fetched comments
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                  `- Retrieved ${comments.length} previous comments\n\n`
                );
                
                // Create a summary of previous comments instead of including full content
                if (comments.length > 0) {
                  allContent += '\n\nPrevious comments summary:';
                  for (const comment of comments) {
                    const commentPreview = comment.body.length > 100 
                      ? comment.body.substring(0, 100) + '...' 
                      : comment.body;
                    allContent += `\n@${comment.author.login} said: ${commentPreview}`;
                  }
                }
              } catch (error) {
                // Log error
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                  `- ❌ Error retrieving previous comments: ${error.message}\n\n`
                );
              }
            }
            
            // Write the full content to a file to preserve all characters exactly
            fs.writeFileSync('content_files/full_content.txt', allContent);
            
            // Also create a base64 version for safe passing
            const base64Content = Buffer.from(allContent).toString('base64');
            fs.writeFileSync('content_files/base64_content.txt', base64Content);
            
            // Log the content handling details
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `- Content written to file: content_files/full_content.txt\n` +
              `- Base64 content written to: content_files/base64_content.txt\n` +
              `- Content length before base64: ${allContent.length} bytes\n` +
              `- Content length after base64: ${base64Content.length} bytes\n\n`
            );
            
            // Set outputs safely
            core.setOutput('discussion_content_base64', base64Content);
            core.setOutput('discussion_content_file', 'content_files/full_content.txt');
            core.setOutput('discussion_id', discussionId);
            core.setOutput('comment_id', commentId);
            
            // Create a short safe version of the content for debugging
            const safeContent = allContent.substring(0, 100).replace(/[^\w\s\.,]/g, '') + '...';
            core.setOutput('discussion_content_safe', safeContent);
      
      - name: Prepare API call with Node.js
        id: prepare-api
        run: |
          echo "### Preparing API call at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          echo "- Model: deepseek-ai/DeepSeek-R1" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create a Node.js script for safe content processing and API payload preparation
          cat > prepare-payload.js << 'EOF'
          const fs = require('fs');
          
          // Log functions
          function log(message) {
            fs.appendFileSync(process.env.LOG_FILE, message + '\n');
          }
          
          try {
            // Read the base64 content and decode it
            log('- Reading base64 content file');
            const base64Content = fs.readFileSync('content_files/base64_content.txt', 'utf8');
            const content = Buffer.from(base64Content, 'base64').toString('utf8');
            
            log(`- Successfully decoded content (${content.length} bytes)`);
            log(`- Content preview: ${content.substring(0, 100)}...`);
            
            // Create the API payload
            log('- Creating API payload');
            const payload = {
              model: "deepseek-ai/DeepSeek-R1",
              messages: [
                {
                  role: "user",
                  content: "Please respond to this discussion: " + content
                }
              ]
            };
            
            // Write the payload to a file
            log('- Writing payload to file');
            fs.writeFileSync('content_files/payload.json', JSON.stringify(payload, null, 2));
            
            // Also create a minimal emergency payload as fallback
            log('- Creating emergency fallback payload');
            const emergencyPayload = {
              model: "deepseek-ai/DeepSeek-R1",
              messages: [
                {
                  role: "user",
                  content: "Please provide a helpful response to a discussion about technology."
                }
              ]
            };
            
            fs.writeFileSync('content_files/emergency_payload.json', JSON.stringify(emergencyPayload, null, 2));
            
            log('- Payload preparation completed successfully');
            console.log('Payload preparation completed successfully');
          } catch (error) {
            log(`- ❌ Error preparing payload: ${error.message}`);
            console.error('Error preparing payload:', error);
            process.exit(1);
          }
          EOF
          
          # Set environment variable for the log file
          export LOG_FILE="${{ steps.init-log.outputs.log_file }}"
          
          # Run the Node.js script
          echo "- Running Node.js script to prepare payload" >> ${{ steps.init-log.outputs.log_file }}
          node prepare-payload.js
          
          if [ $? -ne 0 ]; then
            echo "- ❌ Node.js script failed" >> ${{ steps.init-log.outputs.log_file }}
            exit 1
          fi
          
          echo "- ✅ Payload preparation successful" >> ${{ steps.init-log.outputs.log_file }}
          echo "" >> ${{ steps.init-log.outputs.log_file }}
      
      - name: Call Together AI API
        id: ai-response
        run: |
          echo "### Calling Together AI API at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          
          # Start timer
          START_TIME=$(date +%s)
          
          # Create response directory
          mkdir -p response_files
          
          # Add retry logic for API calls
          MAX_RETRIES=3
          RETRY_COUNT=0
          SUCCESS=false
          
          # Main API calling loop
          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" != "true" ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "- 🔄 Retry attempt $RETRY_COUNT..." >> ${{ steps.init-log.outputs.log_file }}
              sleep $(( RETRY_COUNT * 2 ))  # Progressive backoff
            fi
            
            # Verify the payload file exists
            PAYLOAD_FILE="content_files/payload.json"
            if [ ! -f "$PAYLOAD_FILE" ]; then
              echo "- ❌ Payload file not found, using emergency payload" >> ${{ steps.init-log.outputs.log_file }}
              PAYLOAD_FILE="content_files/emergency_payload.json"
            fi
            
            # Log the payload content (truncated for safety)
            echo "- Payload file: $PAYLOAD_FILE" >> ${{ steps.init-log.outputs.log_file }}
            echo "- Payload preview: $(head -c 200 $PAYLOAD_FILE)..." >> ${{ steps.init-log.outputs.log_file }}
            
            # Use the payload from the file for the API call
            echo "- Sending API request..." >> ${{ steps.init-log.outputs.log_file }}
            RESPONSE_FILE="response_files/api_response_${RETRY_COUNT}.json"
            
            # Make API call and save output to a file
            curl -s -X POST "https://api.together.xyz/v1/chat/completions" \
              -H "Authorization: Bearer ${{ secrets.TOGETHER_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d @"$PAYLOAD_FILE" \
              -o "$RESPONSE_FILE" \
              -w "%{http_code}" > "response_files/status_${RETRY_COUNT}.txt"
            
            # Get HTTP status code
            HTTP_STATUS=$(cat "response_files/status_${RETRY_COUNT}.txt")
            echo "- API request completed with HTTP status: $HTTP_STATUS" >> ${{ steps.init-log.outputs.log_file }}
            
            # Check HTTP status
            if [[ "$HTTP_STATUS" != "2"* ]]; then
              echo "- ❌ API request failed with HTTP status $HTTP_STATUS" >> ${{ steps.init-log.outputs.log_file }}
              echo "- Response preview: $(head -c 200 "$RESPONSE_FILE")..." >> ${{ steps.init-log.outputs.log_file }}
              
              # If this is the last retry and we're still failing, try the emergency payload
              if [[ $RETRY_COUNT -eq $(($MAX_RETRIES-1)) ]]; then
                echo "- 🔄 Final attempt with emergency payload" >> ${{ steps.init-log.outputs.log_file }}
                PAYLOAD_FILE="content_files/emergency_payload.json"
              fi
            else
              # Validate response using jq instead of Node.js
              echo "- Validating response with jq..." >> ${{ steps.init-log.outputs.log_file }}
              
              # Check if jq is available
              if ! command -v jq &> /dev/null; then
                echo "- ⚠️ jq not available, installing..." >> ${{ steps.init-log.outputs.log_file }}
                apt-get update && apt-get install -y jq || brew install jq || true
              fi
              
              # Use jq to check if the response is valid and has the expected structure
              if jq -e '.choices | length > 0 and .[0].message.content' "$RESPONSE_FILE" > /dev/null 2>&1; then
                # Extract the content with jq and save to a file
                jq -r '.choices[0].message.content' "$RESPONSE_FILE" > response_files/content.txt
                CONTENT_SIZE=$(wc -c < response_files/content.txt)
                
                SUCCESS=true
                echo "- ✅ Response validated successfully: content extracted (${CONTENT_SIZE} bytes)" >> ${{ steps.init-log.outputs.log_file }}
                echo "true" > "response_files/validation_success"
              else
                # Check for specific error conditions
                if jq -e '.error' "$RESPONSE_FILE" > /dev/null 2>&1; then
                  ERROR_MSG=$(jq -r '.error.message // "Unknown API error"' "$RESPONSE_FILE")
                  echo "- ❌ API returned error: ${ERROR_MSG}" >> ${{ steps.init-log.outputs.log_file }}
                elif ! jq -e '.choices' "$RESPONSE_FILE" > /dev/null 2>&1; then
                  echo "- ❌ Response missing choices field" >> ${{ steps.init-log.outputs.log_file }}
                elif [ "$(jq '.choices | length' "$RESPONSE_FILE")" -eq "0" ]; then
                  echo "- ❌ Choices array is empty" >> ${{ steps.init-log.outputs.log_file }}
                else
                  echo "- ❌ Response validation failed: missing content or invalid structure" >> ${{ steps.init-log.outputs.log_file }}
                fi
              fi
            fi
            
            RETRY_COUNT=$((RETRY_COUNT+1))
          done
          
          # End timer
          END_TIME=$(date +%s)
          ELAPSED_TIME=$((END_TIME - START_TIME))
          
          echo "- API interaction completed in ${ELAPSED_TIME} seconds" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create the final response content
          if [[ "$SUCCESS" == "true" ]]; then
            # Use the validated content from the validation step
            if [ -f "response_files/content.txt" ]; then
              cat "response_files/content.txt" > response.txt
              echo "- ✅ Using validated API response content" >> ${{ steps.init-log.outputs.log_file }}
              echo "- Response length: $(wc -c < response.txt) bytes" >> ${{ steps.init-log.outputs.log_file }}
            else
              echo "- ⚠️ Validated content file not found" >> ${{ steps.init-log.outputs.log_file }}
              echo "I apologize, but I'm currently experiencing technical difficulties. Your message has been received, and we'll address it as soon as possible." > response.txt
            fi
          else
            # Use a fallback message if all retries failed
            echo "- ❌ All API attempts failed. Using fallback message." >> ${{ steps.init-log.outputs.log_file }}
            echo "I apologize, but I'm currently experiencing technical difficulties. Your message has been received, and we'll address it as soon as possible." > response.txt
            echo "" >> response.txt
            echo "**Note to repository administrators**: The Together AI API request failed. Please check the workflow logs for more details." >> response.txt
          fi
          
          echo "" >> ${{ steps.init-log.outputs.log_file }}
          
          # Set the content as an output in a format that can be used in the next step
          echo "content<<EOF" >> $GITHUB_OUTPUT
          cat response.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      
      - name: Post response to discussion
        id: post-response
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const eventName = context.eventName;
            const discussionId = '${{ steps.get-content.outputs.discussion_id }}';
            const commentId = '${{ steps.get-content.outputs.comment_id }}';
            const aiResponse = `${{ steps.ai-response.outputs.content }}`;
            
            // Log detailed information about what we're posting
            const fs = require('fs');
            
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `### Posting AI Response at ${new Date().toISOString()}\n` +
              `- Event type: ${eventName}\n` +
              `- Discussion ID: ${discussionId}\n` +
              (commentId ? `- Comment ID: ${commentId}\n` : '') +
              `- Response length: ${aiResponse.length} characters\n` +
              `- Response preview: ${aiResponse.substring(0, 100)}...\n\n`
            );
            
            // Validate we have a proper response to post
            if (!aiResponse || aiResponse.trim().length < 3) {
              const errorMsg = 'AI response is empty or too short to post';
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Error: ${errorMsg}\n\n`);
              core.setFailed(errorMsg);
              return;
            }
            
            try {
              // Add a comment with the AI response
              if (eventName === 'discussion') {
                // Add a new comment to the discussion
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Posting new comment to discussion\n`);
                
                function createDiscussionCommentMutation() {
                  return `
                    mutation($discussionId: ID!, $body: String!) {
                      addDiscussionComment(input: {discussionId: $discussionId, body: $body}) {
                        comment {
                          id
                        }
                      }
                    }
                  `;
                }
                
                const result = await github.graphql(createDiscussionCommentMutation(), {
                  discussionId: discussionId,
                  body: aiResponse
                });
                
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                  `- ✅ Successfully posted comment to discussion\n` +
                  `- Comment ID: ${result.addDiscussionComment.comment.id}\n\n`
                );
              } else if (eventName === 'discussion_comment') {
                try {
                  // First try to reply directly to the comment
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Attempting to reply directly to comment\n`);
                  
                  function createReplyMutation() {
                    return `
                      mutation($discussionId: ID!, $body: String!, $replyToId: ID) {
                        addDiscussionComment(input: {discussionId: $discussionId, body: $body, replyToId: $replyToId}) {
                          comment {
                            id
                          }
                        }
                      }
                    `;
                  }
                  
                  const result = await github.graphql(createReplyMutation(), {
                    discussionId: discussionId,
                    body: aiResponse,
                    replyToId: commentId
                  });
                  
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                    `- ✅ Successfully posted reply to comment\n` +
                    `- Reply ID: ${result.addDiscussionComment.comment.id}\n\n`
                  );
                } catch (replyError) {
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                    `- ⚠️ Error replying directly: ${replyError.message}\n` +
                    `- Will try to find parent comment or fallback to a new comment\n`
                  );
                  
                  // Check if this is a "already in thread" error
                  const alreadyInThreadError = replyError.message.includes("Parent comment is already in a thread");
                  fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                    `- Is "already in thread" error: ${alreadyInThreadError}\n`
                  );
                  
                  if (alreadyInThreadError) {
                    try {
                      // Get the discussion to find the parent comment of the thread
                      const { repository } = context.payload;
                      const discussionNumber = context.payload.discussion.number;
                      
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Looking for parent comment in discussion #${discussionNumber}\n`
                      );
                      
                      // First, get the discussion and all its comments and replies
                      function createCommentsQuery() {
                        return `
                          query($owner: String!, $repo: String!, $number: Int!) {
                            repository(owner: $owner, name: $repo) {
                              discussion(number: $number) {
                                comments(first: 100) {
                                  nodes {
                                    id
                                    replies(first: 50) {
                                      nodes {
                                        id
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        `;
                      }
                      
                      const variables = {
                        owner: repository.owner.login,
                        repo: repository.name,
                        number: discussionNumber
                      };
                      
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Querying discussion with variables: ${JSON.stringify(variables)}\n`
                      );
                      
                      const discussionData = await github.graphql(createCommentsQuery(), variables);
                      
                      if (!discussionData || !discussionData.repository || !discussionData.repository.discussion) {
                        throw new Error("Failed to retrieve discussion data");
                      }
                      
                      const comments = discussionData.repository.discussion.comments.nodes;
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Found ${comments.length} top-level comments\n`
                      );
                      
                      // Find a parent comment that contains our comment ID in its replies
                      let parentCommentId = null;
                      
                      // Debug log the comment we're looking for
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- Looking for comment with ID: ${commentId}\n`
                      );
                      
                      for (const comment of comments) {
                        const replies = comment.replies.nodes;
                        fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                          `- Checking comment ${comment.id} with ${replies.length} replies\n`
                        );
                        
                        for (const reply of replies) {
                          if (reply.id === commentId) {
                            parentCommentId = comment.id;
                            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                              `- Match found! Comment ${commentId} is a reply to ${parentCommentId}\n`
                            );
                            break;
                          }
                        }
                        
                        if (parentCommentId) break;
                      }
                      
                      if (parentCommentId) {
                        fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                          `- Found parent comment ID: ${parentCommentId}\n`
                        );
                        
                        // Reply to the parent comment
                        function createParentReplyMutation() {
                          return `
                            mutation($discussionId: ID!, $body: String!, $replyToId: ID!) {
                              addDiscussionComment(input: {discussionId: $discussionId, body: $body, replyToId: $replyToId}) {
                                comment {
                                  id
                                }
                              }
                            }
                          `;
                        }
                        
                        const parentResult = await github.graphql(createParentReplyMutation(), {
                          discussionId: discussionId,
                          body: aiResponse,
                          replyToId: parentCommentId
                        });
                        
                        fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                          `- ✅ Successfully posted reply to parent comment\n` +
                          `- Reply ID: ${parentResult.addDiscussionComment.comment.id}\n\n`
                        );
                      } else {
                        throw new Error("Could not find parent comment for this reply");
                      }
                    } catch (parentError) {
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- ❌ Error finding parent: ${parentError.message}\n` +
                        `- Full error: ${JSON.stringify(parentError)}\n` +
                        `- Falling back to posting a new top-level comment\n`
                      );
                      
                      // Just post a new comment without specifying replyToId
                      function createCommentMutation() {
                        return `
                          mutation($discussionId: ID!, $body: String!) {
                            addDiscussionComment(input: {discussionId: $discussionId, body: $body}) {
                              comment {
                                id
                              }
                            }
                          }
                        `;
                      }
                      
                      const fallbackResult = await github.graphql(createCommentMutation(), {
                        discussionId: discussionId,
                        body: aiResponse
                      });
                      
                      fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                        `- ✅ Successfully posted fallback top-level comment\n` +
                        `- Comment ID: ${fallbackResult.addDiscussionComment.comment.id}\n\n`
                      );
                    }
                  } else {
                    // Log more details about the error
                    fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                      `- ❓ Unknown error type, full error: ${JSON.stringify(replyError)}\n` +
                      `- Falling back to posting a new comment\n`
                    );
                    
                    // For other types of errors, post a new comment
                    function createCommentMutation() {
                      return `
                        mutation($discussionId: ID!, $body: String!) {
                          addDiscussionComment(input: {discussionId: $discussionId, body: $body}) {
                            comment {
                              id
                            }
                          }
                        `;
                    }
                    
                    const fallbackResult = await github.graphql(createCommentMutation(), {
                      discussionId: discussionId,
                      body: aiResponse
                    });
                    
                    fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                      `- ✅ Successfully posted fallback comment\n` +
                      `- Comment ID: ${fallbackResult.addDiscussionComment.comment.id}\n\n`
                    );
                  }
                }
              }
            } catch (error) {
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `- ❌ Error posting response: ${error.message}\n` +
                `- Full error: ${JSON.stringify(error)}\n\n`
              );
              core.setFailed(`Error posting response: ${error.message}`);
            }
      
      - name: Get workflow run logs for analysis
        id: get-logs
        continue-on-error: true  # Don't fail the workflow if this step fails
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { owner, repo } = context.repo;
            const workflowName = 'Discussion Assistant';
            
            const fs = require('fs');
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `### Attempting to Get Workflow Logs at ${new Date().toISOString()}\n`
            );
            
            try {
              // Get workflow ID by name
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Fetching workflows for repo\n`);
              const { data: workflows } = await github.rest.actions.listRepoWorkflows({
                owner,
                repo
              });
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Found ${workflows.workflows.length} workflows\n`);
              
              const workflow = workflows.workflows.find(w => w.name === workflowName);
              if (!workflow) {
                core.warning(`Could not find workflow with name: ${workflowName}`);
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Could not find workflow with name: ${workflowName}\n\n`);
                return 'no_workflow_found';
              }
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Found workflow ID: ${workflow.id}\n`);
              
              // Get workflow runs
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Fetching workflow runs\n`);
              const { data: runs } = await github.rest.actions.listWorkflowRuns({
                owner,
                repo,
                workflow_id: workflow.id,
                per_page: 5  // Get the most recent runs
              });
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Found ${runs.workflow_runs ? runs.workflow_runs.length : 0} workflow runs\n`);
              
              if (!runs.workflow_runs || runs.workflow_runs.length <= 1) {
                core.warning('Not enough workflow runs found for analysis');
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Not enough workflow runs found for analysis\n\n`);
                return 'no_runs_found';
              }
              
              // Get second latest workflow run (to avoid getting the currently running workflow)
              const previousRun = runs.workflow_runs[1];
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Using run ID: ${previousRun.id} (${previousRun.created_at})\n`);
              
              try {
                // Try to get logs URL
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Attempting to download workflow logs\n`);
                const { data: logsUrl } = await github.rest.actions.downloadWorkflowRunLogs({
                  owner,
                  repo,
                  run_id: previousRun.id
                });
                
                // The API returns a URL directly instead of an object with a url property
                const logsDownloadUrl = typeof logsUrl === 'string' ? logsUrl : logsUrl.url;
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Logs URL obtained: ${logsDownloadUrl ? 'Yes' : 'No'}\n`);
                
                if (!logsDownloadUrl) {
                  throw new Error('No logs URL available');
                }
                
                // Download logs using curl
                const { execSync } = require('child_process');
                
                // Download the logs (which is a zip file)
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Downloading logs\n`);
                execSync(`curl -L "${logsDownloadUrl}" -o logs.zip`);
                
                // Create directory for logs
                execSync('mkdir -p workflow_logs');
                
                // Extract the logs
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Extracting logs\n`);
                execSync('unzip -o logs.zip -d workflow_logs');
                
                // Combine all log files into a single file for analysis
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Combining log files\n`);
                execSync('cat workflow_logs/*.txt > combined_logs.txt');
                const logContent = fs.readFileSync('combined_logs.txt', 'utf8');
                
                // Read the workflow file
                const workflowContent = fs.readFileSync('.github/workflows/discussion-assistant.yml', 'utf8');
                
                // Store the content for the next step
                fs.writeFileSync('workflow_file.yml', workflowContent);
                
                // Set outputs in a format that works with GitHub Actions
                core.setOutput('result', 'success');
                core.setOutput('has_logs', 'true');
                
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ✅ Logs and workflow file prepared successfully\n\n`);
                return 'success';
              } catch (logsError) {
                // If we can't get logs, we'll just analyze the workflow file without logs
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Error getting logs: ${logsError.message}\n`);
                
                // Read the workflow file
                const workflowContent = fs.readFileSync('.github/workflows/discussion-assistant.yml', 'utf8');
                
                // Store the content for the next step
                fs.writeFileSync('workflow_file.yml', workflowContent);
                
                // Set outputs in a format that works with GitHub Actions
                core.setOutput('result', 'success');
                core.setOutput('has_logs', 'false');
                
                fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ⚠️ Only workflow file prepared (no logs available)\n\n`);
                return 'success_without_logs';
              }
            } catch (error) {
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- ❌ Error in workflow analysis preparation: ${error.message}\n\n`);
              core.warning(`Error in workflow analysis preparation: ${error.message}`);
              return 'error';
            }
      
      - name: Analyze logs and suggest improvements
        id: analyze-logs
        if: success() && steps.get-logs.outputs.result != ''
        run: |
          echo "### Starting Workflow Analysis at $(date)" >> ${{ steps.init-log.outputs.log_file }}
          
          # Check if the workflow_file.yml exists before proceeding
          if [ ! -f "workflow_file.yml" ]; then
            echo "::warning::workflow_file.yml not found. Skipping analysis."
            echo "- ❌ workflow_file.yml not found. Skipping analysis." >> ${{ steps.init-log.outputs.log_file }}
            exit 0
          fi
          
          echo "- Workflow file found" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create the analysis prompt based on available data
          if [ "${{ steps.get-logs.outputs.has_logs }}" = "true" ] && [ -f "combined_logs.txt" ]; then
            echo "- Using workflow file and logs for analysis" >> ${{ steps.init-log.outputs.log_file }}
            # Get workflow content and logs for analysis
            WORKFLOW_CONTENT=$(cat workflow_file.yml)
            LOG_CONTENT=$(cat combined_logs.txt)
            
            # Create a JSON-safe prompt for analysis
            ANALYSIS_PROMPT="Analyze the following GitHub Action workflow and its execution logs to identify improvements."
            
            # Store the workflow content and logs in files
            echo "$WORKFLOW_CONTENT" > workflow_content.txt
            echo "$LOG_CONTENT" > log_content.txt
            
          else
            echo "- Using only workflow file for analysis (no logs available)" >> ${{ steps.init-log.outputs.log_file }}
            # Only analyze the workflow file without logs
            WORKFLOW_CONTENT=$(cat workflow_file.yml)
            
            # Create a JSON-safe prompt for analysis
            ANALYSIS_PROMPT="Analyze the following GitHub Action workflow configuration to identify improvements."
            
            # Store the workflow content in a file
            echo "$WORKFLOW_CONTENT" > workflow_content.txt
            echo "" > log_content.txt
          fi
          
          # Start timer
          START_TIME=$(date +%s)
          
          echo "- Preparing analysis request to Together AI API" >> ${{ steps.init-log.outputs.log_file }}
          
          # Create JSON payload using jq for proper escaping
          if [ "${{ steps.get-logs.outputs.has_logs }}" = "true" ] && [ -f "combined_logs.txt" ]; then
            PAYLOAD=$(jq -n \
              --arg prompt "$ANALYSIS_PROMPT" \
              --rawfile workflow workflow_content.txt \
              --rawfile logs log_content.txt \
              '{
                "model": "deepseek-ai/DeepSeek-R1",
                "messages": [{
                  "role": "user", 
                  "content": ($prompt + "\n\nWORKFLOW FILE:\n```yaml\n" + $workflow + "\n```\n\nEXECUTION LOGS:\n```\n" + $logs + "\n```\n\nPlease analyze these and identify potential issues, inefficiencies, or improvements. Consider error patterns, performance bottlenecks, best practices, security concerns, reliability improvements, and code quality suggestions. Format your response as a structured GitHub issue with detailed explanations, specific solutions with example code, and benefits of implementing changes.")
                }]
              }')
          else
            PAYLOAD=$(jq -n \
              --arg prompt "$ANALYSIS_PROMPT" \
              --rawfile workflow workflow_content.txt \
              '{
                "model": "deepseek-ai/DeepSeek-R1",
                "messages": [{
                  "role": "user", 
                  "content": ($prompt + "\n\nWORKFLOW FILE:\n```yaml\n" + $workflow + "\n```\n\nPlease analyze this configuration to identify potential issues, inefficiencies, or improvements. Consider best practices, security concerns, reliability improvements, code quality suggestions, and error handling. Format your response as a structured GitHub issue with detailed explanations, specific solutions with example code, and benefits of implementing changes.")
                }]
              }')
          fi
          
          echo "- JSON payload created for analysis" >> ${{ steps.init-log.outputs.log_file }}
          
          # Add retry logic for API calls
          MAX_RETRIES=3
          RETRY_COUNT=0
          SUCCESS=false
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$SUCCESS" != "true" ]; do
            if [ $RETRY_COUNT -gt 0 ]; then
              echo "- 🔄 Retry attempt $RETRY_COUNT for analysis..." >> ${{ steps.init-log.outputs.log_file }}
              sleep $(( RETRY_COUNT * 2 ))  # Progressive backoff
            fi
            
            # Call Together AI API for analysis
            RESPONSE=$(curl -s -X POST "https://api.together.xyz/v1/chat/completions" \
              -H "Authorization: Bearer ${{ secrets.TOGETHER_API_KEY }}" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD")
            
            # Check if the response contains an error - with improved error handling
            ERROR_CHECK=$(echo "$RESPONSE" | jq -r 'if has("error") then .error.message else "no_error" end' 2>/dev/null || echo "json_parse_error")
            
            if [[ "$ERROR_CHECK" == "json_parse_error" ]]; then
              echo "- ⚠️ API returned non-JSON response for analysis (attempt $((RETRY_COUNT+1)))" >> ${{ steps.init-log.outputs.log_file }}
              echo "- Response excerpt: $(echo "$RESPONSE" | head -c 100)..." >> ${{ steps.init-log.outputs.log_file }}
            elif [[ "$ERROR_CHECK" == "no_error" ]]; then
              # First check if the response is valid JSON and has the expected structure
              VALID_JSON=$(echo "$RESPONSE" | jq -r 'if type=="object" and has("choices") then "valid" else "invalid" end' 2>/dev/null || echo "invalid")
              
              if [[ "$VALID_JSON" == "valid" ]]; then
                # Check specific issue: The "choices" key exists but might not be an array (causing "Cannot index string with number" error)
                CHOICES_TYPE=$(echo "$RESPONSE" | jq -r '.choices | type' 2>/dev/null || echo "unknown")
                
                if [[ "$CHOICES_TYPE" != "array" ]]; then
                  echo "- ⚠️ API returned malformed choices structure for analysis (not an array) - attempt $((RETRY_COUNT+1))" >> ${{ steps.init-log.outputs.log_file }}
                  echo "- Choices type: $CHOICES_TYPE" >> ${{ steps.init-log.outputs.log_file }}
                else
                  # Then check if we can extract content safely
                  HAS_CONTENT=$(echo "$RESPONSE" | jq -r '.choices | if length > 0 and (.[0] | has("message")) and (.[0].message | has("content")) then "has_content" else "no_content" end' 2>/dev/null || echo "error")
                  
                  if [[ "$HAS_CONTENT" == "has_content" ]]; then
                    SUCCESS=true
                    echo "- ✅ Valid analysis response received" >> ${{ steps.init-log.outputs.log_file }}
                  else
                    echo "- ⚠️ API returned a valid JSON but missing expected content in analysis (attempt $((RETRY_COUNT+1)))" >> ${{ steps.init-log.outputs.log_file }}
                  fi
                fi
              else
                echo "- ⚠️ API returned invalid JSON structure for analysis (attempt $((RETRY_COUNT+1)))" >> ${{ steps.init-log.outputs.log_file }}
              fi
            else
              echo "- ⚠️ API Error during analysis (attempt $((RETRY_COUNT+1))): $ERROR_CHECK" >> ${{ steps.init-log.outputs.log_file }}
            fi
            
            RETRY_COUNT=$((RETRY_COUNT+1))
          done
          
          # End timer
          END_TIME=$(date +%s)
          ELAPSED_TIME=$((END_TIME - START_TIME))
          
          echo "- Analysis completed in ${ELAPSED_TIME} seconds" >> ${{ steps.init-log.outputs.log_file }}
          
          if [[ "$SUCCESS" == "true" ]]; then
            # Extract the content from the response with added safety
            ANALYSIS=$(echo "$RESPONSE" | jq -r '.choices[0].message.content' 2>/dev/null || echo "")
            
            # Continue with the existing analysis checks
            if [[ -z "$ANALYSIS" || ${#ANALYSIS} -lt 50 ]]; then
              echo "- ⚠️ Analysis too short or empty. No suggestions available." >> ${{ steps.init-log.outputs.log_file }}
              echo "has_suggestions=false" >> $GITHUB_OUTPUT
            else
              # Save the analysis to a file
              echo "$ANALYSIS" > workflow_analysis.txt
              
              # More robust check for meaningful suggestions
              if grep -q -E 'improvement|issue|suggestion|recommend|fix|enhance|optimize|refactor|update|upgrade|modify' workflow_analysis.txt; then
                echo "- ✅ Analysis found suggestions for improvement" >> ${{ steps.init-log.outputs.log_file }}
                echo "has_suggestions=true" >> $GITHUB_OUTPUT
                
                # Format for GitHub output
                echo "analysis<<EOF" >> $GITHUB_OUTPUT
                cat workflow_analysis.txt >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              else
                echo "- ℹ️ No significant suggestions found in analysis" >> ${{ steps.init-log.outputs.log_file }}
                echo "has_suggestions=false" >> $GITHUB_OUTPUT
              fi
            fi
          else
            echo "- ❌ Failed to get analysis after $MAX_RETRIES attempts" >> ${{ steps.init-log.outputs.log_file }}
            echo "has_suggestions=false" >> $GITHUB_OUTPUT
          fi
          
          echo "" >> ${{ steps.init-log.outputs.log_file }}
      
      - name: Create improvement issue
        id: create-issue
        if: steps.analyze-logs.outputs.has_suggestions == 'true'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { owner, repo } = context.repo;
            const analysis = `${{ steps.analyze-logs.outputs.analysis }}`;
            
            const fs = require('fs');
            fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
              `### Creating Improvement Issue at ${new Date().toISOString()}\n`
            );
            
            try {
              // Determine a good title from the analysis (take first line or generate one)
              let title = "Workflow Improvement Suggestions for Discussion Assistant";
              const firstLine = analysis.split('\n')[0].trim();
              if (firstLine && firstLine.length > 10 && firstLine.length < 100) {
                title = firstLine;
              }
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Issue title: "${title}"\n`);
              
              // Get repository owner for assignee
              const { data: repoData } = await github.rest.repos.get({
                owner,
                repo
              });
              
              const assignee = repoData.owner.login;
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', `- Assignee: ${assignee}\n`);
              
              // Create the issue
              const { data: issue } = await github.rest.issues.create({
                owner,
                repo,
                title,
                body: analysis,
                labels: ['automation', 'improvement', 'workflow'],
                assignees: [assignee]
              });
              
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `- ✅ Successfully created issue #${issue.number}\n` +
                `- Issue URL: ${issue.html_url}\n\n`
              );
              
              return {
                issue_number: issue.number,
                issue_url: issue.html_url
              };
            } catch (error) {
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `- ❌ Error creating issue: ${error.message}\n\n`
              );
              core.setFailed(`Error creating issue: ${error.message}`);
              return null;
            }
      
      - name: Create workflow log discussion
        id: create-log-discussion
        if: always()  # Run even if previous steps failed
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { owner, repo } = context.repo;
            
            try {
              const fs = require('fs');
              
              // Append final execution stats
              fs.appendFileSync('${{ steps.init-log.outputs.log_file }}', 
                `\n## Workflow Execution Summary\n` +
                `- End Time: ${new Date().toISOString()}\n` +
                `- Run URL: https://github.com/${owner}/${repo}/actions/runs/${{ github.run_id }}\n` +
                `- Workflow File: https://github.com/${owner}/${repo}/blob/main/.github/workflows/discussion-assistant.yml\n`
              );
              
              // Read the complete log file
              const logContent = fs.readFileSync('${{ steps.init-log.outputs.log_file }}', 'utf8');
              
              // Get available discussion categories
              console.log('Fetching available discussion categories');
              
              const categoriesQuery = `
                query($owner: String!, $repo: String!) {
                  repository(owner: $owner, name: $repo) {
                    discussionCategories(first: 10) {
                      nodes {
                        id
                        name
                      }
                    }
                  }
                }
              `;
              
              let categoryId = null;
              
              try {
                const categoriesResult = await github.graphql(categoriesQuery, { owner, repo });
                const categories = categoriesResult.repository.discussionCategories.nodes;
                
                console.log('Available categories:', categories.map(c => `${c.name} (${c.id})`).join(', '));
                
                // Find an appropriate category - prefer 'Logs' or 'General' or just use the first one
                const logsCategory = categories.find(c => c.name.toLowerCase() === 'logs');
                const generalCategory = categories.find(c => c.name.toLowerCase() === 'general');
                
                categoryId = logsCategory?.id || generalCategory?.id || categories[0]?.id;
                
                console.log(`Selected category: ${categoryId}`);
              } catch (categoriesError) {
                console.error('Error fetching categories:', categoriesError.message);
                // Proceed without a category - will fallback to issues
              }
              
              // Create a new discussion if we have a valid category
              if (categoryId) {
                function createDiscussionMutation() {
                  return `
                    mutation($input: CreateDiscussionInput!) {
                      createDiscussion(input: $input) {
                        discussion {
                          id
                          url
                        }
                      }
                    }
                  `;
                }
                
                const result = await github.graphql(createDiscussionMutation(), {
                  input: {
                    repositoryId: context.payload.repository.node_id,
                    categoryId: categoryId,
                    body: logContent,
                    title: `Analysis of workflow #${{ github.run_number }} - ${new Date().toISOString().split('T')[0]}`
                  }
                });
                
                console.log(`Created log discussion: ${result.createDiscussion.discussion.url}`);
                return result.createDiscussion.discussion.url;
              } else {
                throw new Error('No valid discussion category found');
              }
            } catch (error) {
              console.error(`Error creating log discussion: ${error.message}`);
              
              // If we can't create a discussion through GraphQL, create an issue instead
              try {
                const fs = require('fs');
                const logContent = fs.readFileSync('${{ steps.init-log.outputs.log_file }}', 'utf8');
                
                const { data: issue } = await github.rest.issues.create({
                  owner,
                  repo,
                  title: `Analysis of workflow #${{ github.run_number }} - ${new Date().toISOString().split('T')[0]}`,
                  body: logContent,
                  labels: ['log', 'automation', 'workflow']
                });
                
                console.log(`Created log issue: ${issue.html_url}`);
                return issue.html_url;
              } catch (issueError) {
                console.error(`Error creating fallback log issue: ${issueError.message}`);
                return null;
              }
            } 